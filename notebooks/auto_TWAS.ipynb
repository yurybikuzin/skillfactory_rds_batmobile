{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = 33"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# О проекте\n",
    "\n",
    "Мы работаем в компании, которая занимается продажей автомобилей с пробегом. Основная задача компании и ее менеджеров - максимально быстро находить выгодные предложения (проще говоря, купить ниже рынка, а продать дороже рынка).\n",
    "\n",
    "Нашей команде ([Денис Волков](https://sfdatasciencecourse.slack.com/team/US19J2A64), [Максим Камашев](https://sfdatasciencecourse.slack.com/team/URVGMMG0L) и [Юрий Бикузин](https://sfdatasciencecourse.slack.com/team/U016P0Y3CP7)) поставлена задача создать модель, которая будет предсказывать стоимость автомобиля по его характеристикам.\n",
    "Если наша модель работает хорошо, то мы сможем быстро выявлять выгодные предложения (когда желаемая цена продавца ниже предсказанной рыночной цены). Это значительно ускорит работу менеджеров и повысит прибыль компании.\n",
    "\n",
    "Для проверки нашей модели заказчик придумал нам испытание. Он подготовил [тестовый датасет](https://drive.google.com/u/0/uc?id=18dDPo6GF5VSU2MaIvOk6PFjUnfBi3A42&export=downloa) с таким набором параметров, который будет использоваться для оценки по нашей модели\n",
    "\n",
    "Мы решили внимательно исследовать тестовый датасет, чтобы при подготовить данные, совместимые с ним\n",
    "Для сбора данных мы заранее наметили сайт [Авито](https://www.avito.ru/moskva/transport?cd=1), для которого написали [сканер](https://github.com/yurybikuzin/avito_scanner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Датасет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим трейновый датасет с данными, полученными с Авито:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60028 entries, 0 to 60027\n",
      "Data columns (total 77 columns):\n",
      " #   Column                                Non-Null Count  Dtype  \n",
      "---  ------                                --------------  -----  \n",
      " 0   bodyType                              59979 non-null  object \n",
      " 1   brand                                 59979 non-null  object \n",
      " 2   color                                 60028 non-null  object \n",
      " 3   fuelType                              59979 non-null  object \n",
      " 4   name                                  59979 non-null  object \n",
      " 5   title                                 0 non-null      float64\n",
      " 6   numberOfDoors                         59977 non-null  float64\n",
      " 7   productionDate                        60024 non-null  float64\n",
      " 8   vehicleTransmission                   59979 non-null  object \n",
      " 9   engineDisplacement                    59682 non-null  object \n",
      " 10  enginePower                           60012 non-null  object \n",
      " 11  description                           60028 non-null  object \n",
      " 12  mileage                               60028 non-null  int64  \n",
      " 13  Привод                                59979 non-null  object \n",
      " 14  Руль                                  59908 non-null  object \n",
      " 15  Состояние                             60028 non-null  object \n",
      " 16  Владельцы                             60028 non-null  object \n",
      " 17  Электростеклоподъемники               8039 non-null   object \n",
      " 18  Усилитель руля                        8299 non-null   object \n",
      " 19  Аудиосистема                          5143 non-null   object \n",
      " 20  Фары                                  1273 non-null   object \n",
      " 21  Климат-контроль                       4561 non-null   object \n",
      " 22  Салон                                 3338 non-null   object \n",
      " 23  Диски                                 6933 non-null   object \n",
      " 24  autoCatalogUrl                        59311 non-null  object \n",
      " 25  itemPrice                             60028 non-null  int64  \n",
      " 26  marketPrice                           25662 non-null  float64\n",
      " 27  status                                628 non-null    object \n",
      " 28  closingReason                         628 non-null    object \n",
      " 29  complectation                         27859 non-null  object \n",
      " 30  modification                          30924 non-null  object \n",
      " 31  generation                            30924 non-null  object \n",
      " 32  typeOfTrade                           60028 non-null  object \n",
      " 33  canonicalUrl                          60028 non-null  object \n",
      " 34  autocatalogId                         59248 non-null  float64\n",
      " 35  autocatalogTitle                      59248 non-null  object \n",
      " 36  autocatalogTransmission               59220 non-null  object \n",
      " 37  autocatalogEngineDisplacement         59220 non-null  float64\n",
      " 38  autocatalogEngineDisplacementPrecise  59215 non-null  float64\n",
      " 39  autocatalogDrive                      59220 non-null  object \n",
      " 40  autocatalogFuelType                   59220 non-null  object \n",
      " 41  autocatalogEnginePower                59220 non-null  float64\n",
      " 42  autocatalogMaximumSpeed               49844 non-null  float64\n",
      " 43  autocatalogAcceleration               48200 non-null  object \n",
      " 44  autocatalogBrandCountry               59178 non-null  object \n",
      " 45  autocatalogAssemblyCountry            22992 non-null  object \n",
      " 46  autocatalogNumberOfSeats              52179 non-null  object \n",
      " 47  autocatalogRating                     9768 non-null   object \n",
      " 48  autocatalogNumberOfCylinders          52117 non-null  object \n",
      " 49  autocatalogConfiguration              52104 non-null  object \n",
      " 50  autocatalogTorque                     51854 non-null  object \n",
      " 51  autocatalogTorqueMax                  51538 non-null  object \n",
      " 52  autocatalogMaxPowerSpeed              51693 non-null  object \n",
      " 53  autocatalogHeight                     52055 non-null  float64\n",
      " 54  autocatalogLength                     52082 non-null  float64\n",
      " 55  autocatalogTurningDiameter            2955 non-null   float64\n",
      " 56  autocatalogClearance                  48891 non-null  object \n",
      " 57  autocatalogWheelbase                  52072 non-null  float64\n",
      " 58  autocatalogRearTrack                  32871 non-null  float64\n",
      " 59  autocatalogFrontTrack                 32876 non-null  float64\n",
      " 60  autocatalogTrunkVolume                47636 non-null  object \n",
      " 61  autocatalogFuelTankCapacity           51807 non-null  float64\n",
      " 62  autocatalogFuelConsumptionCity        46951 non-null  float64\n",
      " 63  autocatalogFuelConsumptionHighway     46512 non-null  object \n",
      " 64  autocatalogFuelConsumptionMixed       45427 non-null  object \n",
      " 65  autocatalogEnvironmentalClass         30415 non-null  object \n",
      " 66  autocatalogRearBreaks                 52023 non-null  object \n",
      " 67  autocatalogFrontBreaks                52184 non-null  object \n",
      " 68  autocatalogRearTireDimension          50514 non-null  object \n",
      " 69  autocatalogFrontTireDimension         50520 non-null  object \n",
      " 70  autocatalogRearSuspension             22793 non-null  object \n",
      " 71  autocatalogFrontSuspension            22723 non-null  object \n",
      " 72  autocatalogWorldPremier               3987 non-null   object \n",
      " 73  autocatalogPendingUpdate              3943 non-null   object \n",
      " 74  autocatalogWidthWithMirrors           1492 non-null   float64\n",
      " 75  autocatalogRearDiscDimension          2351 non-null   object \n",
      " 76  autocatalogFrontDiscDimension         2355 non-null   object \n",
      "dtypes: float64(18), int64(2), object(57)\n",
      "memory usage: 35.3+ MB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import re\n",
    "\n",
    "is_debug = False\n",
    "if not is_debug:\n",
    "    # train_dataset_url=\"https://drive.google.com/u/0/uc?id=1HFV1106xXhrnNt5wG1nXl0X-b5Jql2Md&export=download\"\n",
    "    train_dataset_url=\"https://drive.google.com/u/0/uc?id=1MaX59-keo_h4TEGKwW-HO7Ehh_O2wVwu&export=download\"\n",
    "    train_orig = pd.read_csv(train_dataset_url, low_memory = False)\n",
    "train = train_orig.copy()\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим тестовый датасет (мы его предварительно разместили на Google Drive, чтобы к нему можно было обращаться по ссылке):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3837 entries, 0 to 3836\n",
      "Data columns (total 23 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   bodyType              3837 non-null   object \n",
      " 1   brand                 3837 non-null   object \n",
      " 2   color                 3837 non-null   object \n",
      " 3   fuelType              3837 non-null   object \n",
      " 4   modelDate             3837 non-null   float64\n",
      " 5   name                  3837 non-null   object \n",
      " 6   numberOfDoors         3837 non-null   float64\n",
      " 7   productionDate        3837 non-null   float64\n",
      " 8   vehicleConfiguration  3837 non-null   object \n",
      " 9   vehicleTransmission   3837 non-null   object \n",
      " 10  engineDisplacement    3837 non-null   object \n",
      " 11  enginePower           3837 non-null   object \n",
      " 12  description           3837 non-null   object \n",
      " 13  mileage               3837 non-null   float64\n",
      " 14  Комплектация          3837 non-null   object \n",
      " 15  Привод                3837 non-null   object \n",
      " 16  Руль                  3837 non-null   object \n",
      " 17  Состояние             3837 non-null   object \n",
      " 18  Владельцы             3837 non-null   object \n",
      " 19  ПТС                   3837 non-null   object \n",
      " 20  Таможня               3837 non-null   object \n",
      " 21  Владение              1753 non-null   object \n",
      " 22  id                    3837 non-null   int64  \n",
      "dtypes: float64(4), int64(1), object(18)\n",
      "memory usage: 689.6+ KB\n"
     ]
    }
   ],
   "source": [
    "if not is_debug:\n",
    "    test_dataset_url=\"https://drive.google.com/u/0/uc?id=18dDPo6GF5VSU2MaIvOk6PFjUnfBi3A42&export=download\"\n",
    "    test_orig = pd.read_csv(test_dataset_url)\n",
    "test = test_orig.copy()\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нем только одно частично заполненное поле: `Владение`, все остальные поля полностью заполнены"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Целью нашего рассмотрения тестового и трейнового датасетов будет отбор таких полей из обоих, чтобы можно было скомпоновать единый датасет на основе теста и трейна, с общим набороом колонок\n",
    "\n",
    "При формировании колонок единого датасета тон будет задавать именно тестовый датасет, потому что он содержит поля, по которым закачик будет проверять валидность нашей модели и далее использовать ее на практике\n",
    "\n",
    "После формирования единого датасета мы уже из него выделим новый трейновый, обучим на нем модель, а потом прогоним на ней новой тестовый датасет, выделенный из единого, чтобы получить submission для kaggle, где заказчик будет проверять валидность построенной нами модели\n",
    "\n",
    "Поэтому далее мы просматриваем поля именно тестового датасета, пытаясь подобрать подходящие данные из трейнового\n",
    "\n",
    "В переменной `common_cols` будем накапливать список общих колонок для единого датасета:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_cols = set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим вспомогательную функцию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe(df, field_name):\n",
    "    print(f\"Колонка \\\"{field_name}\\\":\")\n",
    "    print(\"------\")\n",
    "    print(\"na:\", df[field_name].isna().sum())\n",
    "    print(\"уникальных значений:\", len(df[field_name].unique()))\n",
    "    print(\"------\")\n",
    "    print(df[field_name].value_counts())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bodyType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = test\n",
    "field_name = 'bodyType'\n",
    "describe(df, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратим внимание на то, что есть значения, например \"xэтчбек 5 дв.\", который совпадают с другим значением \"хэтчбек\", но имеют дополнительно указание количества дверей\n",
    "\n",
    "Поскольку у нас есть отдельное полей `numberOfDoors`, содержащее количество дверей, то давайте проверим, есть ли расхождение в количестве дверей в этом поле со значением, указанным в поле bodyType:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(x):\n",
    "    ss = str(x).split()\n",
    "    if len(ss) > 2:\n",
    "        return float(ss[1])\n",
    "    else:\n",
    "        return None\n",
    "df['дв'] = df[field_name].apply(lambda x: extract(x))\n",
    "print(df[ (df['дв'].notna()) & (df['дв'] != df.numberOfDoors) ]['дв'].count())\n",
    "df.drop(['дв'], inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что расхождений нет, а значит составные значений поля `bodyType`, такие как \"хэтчбек 5 дв.\", содержат информацию, дублирующую в поле `numberOfDoors`, а значит, мы можем очистить составные значения поля `bodyType` от этой дублирующей информации и сократить количество разных значений поля:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df[field_name] = df[field_name].apply(lambda x: str(x).split()[0])\n",
    "describe(df, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В трейне есть колонка с тем жем названием:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "describe(train, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако набор значений немного отличается:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = set(train[train[field_name].notna()][field_name].unique().tolist())\n",
    "b = set(test[field_name].unique().tolist())\n",
    "print(\"Общие значения:\", a.intersection(b))\n",
    "print(\"Значения, которых нет в тесте:\", a - b)\n",
    "print(\"Значения, которых нет в трейне:\", b - a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"лифтбек\" - это [разновидность](https://avtovikup136.ru/topics/%D1%82%D0%B8%D0%BF-%D0%BA%D1%83%D0%B7%D0%BE%D0%B2%D0%B0-%D0%BB%D0%B8%D1%84%D1%82%D0%B1%D0%B5%D0%BA-%D1%87%D1%82%D0%BE-%D1%8D%D1%82%D0%BE/) \"хэтчбека\"\n",
    "\n",
    "\"компактвэн\" и \"минивэн\" - это [достаточно близкие](https://autozam.ru/klassi-avtomobiley/odin-na-semerich-mini-i-kompaktveni.html) понятия\n",
    "\n",
    "а \"родстер\" - \"Термин часто используется просто как коммерческое название двухдверного двухместного кабриолета\" ([источник](https://ru.wikipedia.org/wiki/%D0%A0%D0%BE%D0%B4%D1%81%D1%82%D0%B5%D1%80))\n",
    "\n",
    "Произведем соответствующие замены:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unify(x):\n",
    "    if x == \"лифтбек\":\n",
    "        return \"хэтчбек\"\n",
    "    elif x == \"компактвэн\":\n",
    "        return \"минивэн\"\n",
    "    elif x == \"родстер\":\n",
    "        return \"кабриолет\"\n",
    "    else:\n",
    "        return x\n",
    "df[field_name] = df[field_name].apply(unify)\n",
    "describe(df, field_name)\n",
    "a = set(train[train[field_name].notna()][field_name].unique().tolist())\n",
    "b = set(test[field_name].unique().tolist())\n",
    "print(\"Общие значения:\", a.intersection(b))\n",
    "print(\"Значения, которых нет в тесте:\", a - b)\n",
    "print(\"Значения, которых нет в трейне:\", b - a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, мы привели колонки `bodyType` теста и трейна к общему знаменателю (трейна)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим рассматриваемую колонку в список колонок единого датасета:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_cols.add(field_name)\n",
    "common_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_name = 'brand'\n",
    "describe(df, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что тестовая выборка монобрендовая. Однако мы будем готовить полибрендовые данные для обучения, так как мы помним, что наша задача - создать модель для быстрого выкупа автомобилей, а тестовая выборка предназначена лишь для проверки нашей модели, сама же модель будет использоватся для разных брендов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В трейне есть поле с тем же названием:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "describe(train, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим рассматриваемую колонку в список колонок единого датасета:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_cols.add(field_name)\n",
    "common_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "field_name = 'color'\n",
    "describe(df, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В трейне есть поле с тем же названием:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(train, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для приведения к общему знаменателю достаточно перевести значения в трейне в нижний регистр:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train[field_name] = train[field_name].apply(lambda x: None if pd.isna(x) else x.lower())\n",
    "describe(train, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим рассматриваемую колонку в список колонок единого датасета:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_cols.add(field_name)\n",
    "common_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fuelType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_name = 'fuelType'\n",
    "describe(df, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В трейне есть поле с тем же названием:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "describe(train, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для приведения к общему знаменателю достаточно перевести значения в трейне в нижний регистр:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train[field_name] = train[field_name].apply(lambda x: None if pd.isna(x) else x.lower())\n",
    "describe(train, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим рассматриваемую колонку в список колонок единого датасета:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_cols.add(field_name)\n",
    "common_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### modelDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "field_name = 'modelDate'\n",
    "describe(df, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поля с тем же именем в трейне нет, но есть поле `autocatalogWorldPremier`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(train, 'autocatalogWorldPremier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из которой можно извлечь нужную информацию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def extract(x):\n",
    "    found_year = re.search('(\\d\\d\\d\\d)', x)\n",
    "    if found_year:\n",
    "        return int(found_year.group(1))\n",
    "    else:\n",
    "        return None   \n",
    "train[field_name] = train['autocatalogWorldPremier'].apply(lambda x: None if pd.isna(x) else extract(x))\n",
    "describe(train, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но, к сожалению, в этом поле слишком много пропусков, поэтому мы вынуждены его проигнорировать"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_name = 'name'\n",
    "describe(df, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что поле `name` содержит составные значения\n",
    "\n",
    "Попробуем разобрать эти значения на запчасти\n",
    "\n",
    "Сначала выделим признак полного привода в отдельное поле:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['4WD'] = df[field_name].apply(lambda x: 1 if \"4WD\" in x else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А отметку этого признака уберем из поля `name`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[field_name] = df[field_name].apply(lambda x: x[:-4] if x.endswith(' 4WD') else x)\n",
    "describe(df, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Затем обратим внимание на то, что у нас есть отдельное поле `enginePower`, тоже содержащее количество лошадиных сил, указанное в скобках в значении рассматриваемого нами поля `name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.enginePower.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте убедимся, что количество лошадиных сил в поле `name` просто дублирует значение поля `enginePower`, проверив, есть ли расхождения в значениях:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = 'л.с. из enginePower'\n",
    "B = 'л.с. из name'\n",
    "df[A] = df.enginePower.apply(lambda x: int(x.split()[0]))\n",
    "def extract(x):\n",
    "    found_engine_power = re.search('\\((\\d+)\\s*л\\.\\с\\.\\)', x)\n",
    "    if found_engine_power:\n",
    "        return int(found_engine_power.group(1))\n",
    "    else:\n",
    "        return None\n",
    "df[B] = df[field_name].apply(lambda x: extract(x))\n",
    "print(\"Расхождений в лошадиных силах:\", df[ (df[B].notna()) & (df[B] != df[A]) ][B].count())\n",
    "df.drop([A, B], inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, расхождений нет, поэтому смело можем убрать количество лошадиных сил из значений поля `name`, так как для этого есть отдельное поле `enginePower`, которое содержит совпадающее значение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_suffix(x):\n",
    "    x = re.sub('\\s*\\((\\d+)\\s*л\\.\\с\\.\\)$', '', x)\n",
    "    return x\n",
    "df[field_name] = df[field_name].apply(lambda x: drop_suffix(x))\n",
    "describe(df, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас осталось одно значение в поле `name`, в котором мощность указана не лошадиных силах, а в киловаттах: \"Electro AT (126 кВт)\"\n",
    "\n",
    "Давайте посмотрим, что указано в поле enginePower для этой записи:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df[field_name].str.contains('кВт'))].enginePower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Указана мощность в 170 лошадиных сил, но это, согласно [калькулятору перевода лошадиных сил в киловатты](https://www.google.com/search?q=%D0%BA%D0%B8%D0%BB%D0%BE%D0%B2%D0%B0%D1%82%D1%82%D1%8B+%D0%B2+%D0%BB%D0%BE%D1%88%D0%B0%D0%B4%D0%B8%D0%BD%D1%8B%D0%B5+%D1%81%D0%B8%D0%BB%D1%8B&oq=%D0%BA%D0%B8%D0%BB%D0%BE%D0%B2%D0%B0%D1%82%D1%82%D1%8B), в точности совпадает со 126 кВт мощности, указанному в значении поля `name`\n",
    "\n",
    "Поэтому и в этом случае можно очистить значение поля `name` от дублирующей информации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_suffix(x):\n",
    "    x = re.sub('\\s*\\((\\d+)\\s*кВт\\)$', '', x)\n",
    "    return x\n",
    "df[field_name] = df[field_name].apply(lambda x: drop_suffix(x))\n",
    "describe(df, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь обратим внимание на суффикс \"AT\"/\"МТ\"\n",
    "\n",
    "Если соотнести его присутствие в значении поля `name` со значеним поля `vehicleTransmission`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Трансмиссии: \", df.vehicleTransmission.unique())\n",
    "df[df[field_name].str.contains(\"[AM]T\", regex=True)][[field_name, 'vehicleTransmission']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То можно предположить, что этот суффикс дублирует информацию из поля `vehicleTransmission`\n",
    "Давайте проверим это предположение, проверив отсутствие расхожений значения трансмисии, извлеченной из поля `name`, со значением, указанным в поле `vehicleTransmission`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = 'трансмиссия из поля name'\n",
    "df[A] = df[field_name].apply(lambda x: 'автоматическая' if \"AT\" in x else 'механическая' if \"MT\" in x else None)\n",
    "print(\"Расхождений в трансмиссии:\", df[ (df[A].notna()) & (df[A] != df.vehicleTransmission) ][A].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Упс! Обнаружены расхождения\n",
    "\n",
    "Значит, наше предположение о полном соответствии трансмиссии, указанной в поле `name`, со значением в поле 'vehicleTransmission' неверно\n",
    "\n",
    "Или неверно лишь в том виде, в котором мы его сделали\n",
    "\n",
    "Давайте проверим строки, в которых это расхождение обнаружено:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[ (df[A].notna()) & (df[A] != df.vehicleTransmission) ][['name', 'vehicleTransmission']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно увидеть, что есть третий суффикс \"AMT\", который мы не выделили сразу, но он, похоже, соответствует значению трансмиссии \"роботизированная\". Выходит, наше изначальное предположение было лишь неполным, а не неверным\n",
    "\n",
    "Давайте проверим, что есть соответствие \"AT\" => \"автоматическая\", \"МТ\" => \"механическая\", \"АМТ\" => \"роботизированная\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = 'трансмиссия из поля name'\n",
    "def extract(x):\n",
    "    if \"AMT\" in x:\n",
    "        return 'роботизированная'  \n",
    "    elif \"AT\" in x:\n",
    "        return 'автоматическая'\n",
    "    elif \"MT\" in x:\n",
    "        return 'механическая'\n",
    "    else:\n",
    "        return None    \n",
    "df[A] = df[field_name].apply(lambda x: extract(x))\n",
    "print(\"Расхождений в трансмиссии:\", df[ (df[A].notna()) & (df[A] != df.vehicleTransmission) ][A].count())\n",
    "df.drop([A], inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Расхождений нет\n",
    "\n",
    "Значит наше предполжение оправдано, и можно очистить значение поля `name` от лишнего суффикса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_suffix(x):\n",
    "    x = re.sub('\\s[AM]+T$', '', x)\n",
    "    return x\n",
    "df[field_name] = df[field_name].apply(lambda x: drop_suffix(x))\n",
    "describe(df, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратим внимание на суффикс, например \"3.0d\", похожий на вещественное число, иногда сопровождаемый буквенным кодом\n",
    "\n",
    "Давайте посмотрим, какими еще буквами сопровождается вещественное число в значении поля `name`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(x):\n",
    "    found_suffix = re.search('\\d+\\.\\d(\\w+)$', x)\n",
    "    if found_suffix:\n",
    "        return found_suffix.group(1)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "list(set(filter(lambda x: x is not None, map(extract, df[field_name].unique().tolist()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если соотнести буквенный код со значениями в поле `fuelType`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = 'code'\n",
    "df[A] = df[field_name].apply(lambda x: extract(x))\n",
    "print(df[ (df[A].notna()) & (df[A] == 'd') ][[A, 'fuelType']])\n",
    "print(df[ (df[A].notna()) & (df[A] == 'hyb') ][[A, 'fuelType']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То можно увидеть, что код, если указан, всегда дублирует значение поля `fuelType`\n",
    "\n",
    "Проверим это предположение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 'fuelType по коду'\n",
    "df[B] = df[A].apply(lambda x: 'дизель' if x == 'd' else 'гибрид' if x == 'hyb' else None)\n",
    "print(\"Расхождений в типе топлива:\", df[ (df[B].notna()) & (df[B] != df.fuelType) ][B].count())\n",
    "df.drop([A, B], inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если соотнести вещественное число со значениями полей `engineDisplacement` (объем двигателя):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[field_name, 'engineDisplacement']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То можно заметить соответствие этого вещественного числа значению поля `engineDisplacement`\n",
    "\n",
    "Проверим этo предположения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "A = 'объем двигателя из name'\n",
    "B = 'объем двигателя из engineDisplacement'\n",
    "\n",
    "def extract_engine_displacement(x, regex):\n",
    "    found_engine_displacement = re.search(regex, x)\n",
    "    if found_engine_displacement:\n",
    "        return float(found_engine_displacement.group(1))\n",
    "    else:\n",
    "        return None\n",
    "df[A] = df[field_name].apply(lambda x: extract_engine_displacement(x, '\\s*(\\d+\\.\\d)(\\D.*)$'))\n",
    "df[B] = df.engineDisplacement.apply(lambda x: extract_engine_displacement(x, '^(\\d+\\.\\d)'))\n",
    "print(\"Расхождений в объеме двигателя:\", df[ (df[A].notna()) & (df[A] != df[B]) ][A].count())\n",
    "df[ (df[A].notna()) & (df[A] != df[B]) ][[A, B]]\n",
    "df.drop([A, B], inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обнаружено одно расхождение, но им в данном случае можно пренебречь (оно в пределах погрешности), и очистить поле `name` от суффикса с вещественным числом с буквенным кодом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следовательно, можно очистить значение поля `name` и от суффикса в виде вещественного числа с буквенным кодом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_suffix(x):\n",
    "    x = re.sub('\\s*\\d+\\.\\d\\w*$', '', x)\n",
    "    return x\n",
    "df[field_name] = df[field_name].apply(lambda x: drop_suffix(x))\n",
    "describe(df, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим оставшиеся уникальные значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[field_name].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратим на присутствие кодов \"xDrive\" и \"sDrive\". \"xDrive\" - это код [системы интеллектуального полного привода](https://techautoport.ru/transmissiya/sistemy-polnogo-privoda/xdrive.html), а \"sDrive\" - это код системы заднего привода\n",
    "\n",
    "Вынесем коды привода в отдельные поля:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['xDrive'] = df[field_name].apply(lambda x: 1 if \"xDrive\" in x else 0)\n",
    "df['sDrive'] = df[field_name].apply(lambda x: 1 if \"sDrive\" in x else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И очистим значение поля `name` от этого кода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_suffix(x):\n",
    "    x = re.sub('[xs]Drive', '', x)\n",
    "    return x\n",
    "df[field_name] = df[field_name].apply(lambda x: drop_suffix(x))\n",
    "describe(df, field_name)\n",
    "df[field_name].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате в поле `name` у нас остались модели BMW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['model'] = df[field_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В трейне поле `name` содержит другую информацию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(train, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Информацию похожую на искомую содержит поле `autocatalogTitle`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[(train.brand == \"BMW\")]['autocatalogTitle'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Произведем обработку трейне, аналогичную той, что мы произвели для рассматриваемого поля в тесте:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_temp = df\n",
    "field_name_temp = field_name\n",
    "try:\n",
    "    df = train\n",
    "    field_name = 'autocatalogTitle'\n",
    "#     df[field_name] = train_orig[field_name]\n",
    "    def drop_suffix(x):\n",
    "        x = re.sub('\\s*\\((\\d+)\\s*л\\.\\с\\.?\\s*\\)', '', x)\n",
    "        x = re.sub('\\s[AM]+T', '', x)\n",
    "        return x\n",
    "    df[field_name] = df[field_name].apply(lambda x: None if pd.isna(x) else drop_suffix(x))\n",
    "    df['4WD'] = df[field_name].apply(lambda x: 1 if pd.notna(x) and 'AWD' in x else 0)\n",
    "    df['FWD'] = df[field_name].apply(lambda x: 1 if pd.notna(x) and 'FWD' in x else 0)\n",
    "    df['RWD'] = df[field_name].apply(lambda x: 1 if pd.notna(x) and 'RWD' in x else 0)\n",
    "    df['4WD'] = df[field_name].apply(lambda x: 1 if pd.notna(x) and re.match(r'quattro|4(?:WD|MATIC|x?Motion)', x, flags=re.IGNORECASE) else 0)\n",
    "    df['xDrive'] = df[field_name].apply(lambda x: 1 if pd.notna(x) and \"xDrive\" in x else 0)\n",
    "    df['sDrive'] = df[field_name].apply(lambda x: 1 if pd.notna(x) and \"sDrive\" in x else 0)\n",
    "    df['eDrive'] = df[field_name].apply(lambda x: 1 if pd.notna(x) and \"eDrive\" in x else 0)\n",
    "    df['tronic'] = df[field_name].apply(lambda x: 1 if pd.notna(x) and (\"tronic\" in x or \"Tronic\" in x) else 0)\n",
    "    def drop_suffix(x):\n",
    "        x = re.sub('\\s*[ARF]WD', '', x)\n",
    "        x = re.sub('\\s*4(x?motion|matic|wd)', '', x, flags=re.IGNORECASE)\n",
    "        x = re.sub('\\s*quattro', '', x)\n",
    "        x = re.sub('\\s*[xes]Drive', '', x)\n",
    "        x = re.sub('\\s*(?:Step|Tip|Multi)tronic', '', x)\n",
    "        x = re.sub('\\s*\\d+G-Tronic', '', x, flags=re.IGNORECASE)\n",
    "        return x\n",
    "    df[field_name] = df[field_name].apply(lambda x: None if pd.isna(x) else drop_suffix(x))\n",
    "    def drop_suffix(x):\n",
    "        x = re.sub('\\s*\\d+\\.\\d\\w*$', '', x)\n",
    "        return x\n",
    "    df[field_name] = df[field_name].apply(lambda x: None if pd.isna(x) else drop_suffix(x))\n",
    "    print(\"Получившиеся модели BMW:\", df[(df.brand == \"BMW\")][field_name].unique().tolist())\n",
    "    print(\"------------------------\")\n",
    "    print(\"Получившиеся модели остальных брендов:\", df[(df.brand != \"BMW\")][field_name].unique().tolist())\n",
    "finally:\n",
    "    df = df_temp\n",
    "    field_name = field_name_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также поместим полученный результат в поле `model`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['model'] = train['autocatalogTitle']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим в список колонок единого датасета следующие колонки: `model`, `xDrive`, `sDrive`, `4WD`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for field_name in ['model', 'xDrive', 'sDrive', '4WD']:\n",
    "    common_cols.add(field_name)\n",
    "common_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### numberOfDoors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_name = 'numberOfDoors'\n",
    "describe(df, field_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "describe(train, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим рассматриваемую колонку в список колонок единого датасета:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_cols.add(field_name)\n",
    "common_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### productionDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_name = 'productionDate'\n",
    "describe(df, field_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "describe(train, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим рассматриваемую колонку в список колонок единого датасета:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_cols.add(field_name)\n",
    "common_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vehicleConfiguration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_name = 'vehicleConfiguration'\n",
    "describe(df, field_name)\n",
    "df[field_name].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь мы, как и в поле `name`, наблюдаем составное значение\n",
    "\n",
    "Очень похоже, что последнее вещественное числов значение - это объем двигателя, который есть в отдельном поле `engineDisplacement`, \"AUTOMATIC\"/\"MECHANICAL\" - это тип трансмиссии, который есть в отдельном поле `vehicleTransmission`, а первое \"слово\" в этом составном значении - это тип кузова (`bodyType`) дополненный значением `numberOfDoors`\n",
    "\n",
    "Проверим наше предположение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = 'объем двигателя из vehicleConfiguration'\n",
    "B = 'объем двигателя из engineDisplacement'\n",
    "C = 'трансмиссия из vehicleConfiguration'\n",
    "D = 'количество дверей из vehicleConfiguration'\n",
    "E = 'тип кузова из vehicleConfiguration'\n",
    "def extract_engine_displacement(x, regex):\n",
    "    found_engine_displacement = re.search(regex, x)\n",
    "    if found_engine_displacement:\n",
    "        return float(found_engine_displacement.group(1))\n",
    "    else:\n",
    "        return None\n",
    "df[A] = df[field_name].apply(lambda x: extract_engine_displacement(x, '\\s*(\\d+\\.\\d)(\\D.*)$'))\n",
    "df[B] = df.engineDisplacement.apply(lambda x: extract_engine_displacement(x, '^(\\d+\\.\\d)'))\n",
    "print(\"Расхождений в объеме двигателя:\", df[ (df[A].notna()) & (df[A] != df[B]) ][A].count())\n",
    "print(\"Варианты трансмиссии из vehicleConfiguration:\", set(list(map(lambda x: x.split()[1], df[field_name].unique()))))\n",
    "def extract_vehicle_transmission(x):\n",
    "    ss = x.split()\n",
    "    if len(ss) < 2:\n",
    "        return None\n",
    "    else:\n",
    "        s = ss[1]\n",
    "        if s == 'ROBOT':\n",
    "            return 'роботизированная'\n",
    "        elif s == 'MECHANICAL':\n",
    "            return 'механическая'\n",
    "        elif s == 'AUTOMATIC':\n",
    "            return 'автоматическая'\n",
    "        else:\n",
    "            return 'Unknown'\n",
    "df[C] = df[field_name].apply(lambda x: extract_vehicle_transmission(x))\n",
    "print(\"Расхождений в трансмиссии:\", df[ (df[C].notna()) & (df[C] != df.vehicleTransmission) ][C].count())\n",
    "def extract_number_of_doors(x):\n",
    "    ss = x.split()\n",
    "    if len(ss) < 1:\n",
    "        return None\n",
    "    else:\n",
    "        s = ss[0]\n",
    "        found_number_of_doors = re.search('_(\\d+)_DOORS', s)\n",
    "        if found_number_of_doors:\n",
    "            return int(found_number_of_doors.group(1))\n",
    "        else:\n",
    "            return None\n",
    "df[D] = df[field_name].apply(lambda x: extract_number_of_doors(x))\n",
    "print(\"Расхождений в количестве дверей:\", df[ (df[D].notna()) & (df[D] != df.numberOfDoors) ][D].count())\n",
    "df[D].unique()\n",
    "def extract_body_type(x):\n",
    "    ss = x.split()\n",
    "    if len(ss) < 1:\n",
    "        return None\n",
    "    else:\n",
    "        s = ss[0]\n",
    "        ss = s.split('_')\n",
    "        if len(ss) < 1:\n",
    "            return None\n",
    "        else:\n",
    "            return ss[0]\n",
    "print(\"Варианты типа кузова из vehicleConfiguration:\", \n",
    "      set(list(map(lambda x: extract_body_type(x), df[field_name].unique())))\n",
    ")\n",
    "def extract_body_type_rus(x):\n",
    "    s = extract_body_type(x)\n",
    "    if s is None:\n",
    "        return None\n",
    "    elif s == 'ROADSTER':\n",
    "        return 'родстер'\n",
    "    elif s == 'HATCHBACK':\n",
    "        return 'хэтчбек'\n",
    "    elif s == 'LIFTBACK':\n",
    "        return 'лифтбек'\n",
    "    elif s == 'COMPACTVAN':\n",
    "        return 'компактвэн'\n",
    "    elif s == 'CABRIO':\n",
    "        return 'кабриолет'\n",
    "    elif s == 'SEDAN':\n",
    "        return 'седан'\n",
    "    elif s == 'COUPE':\n",
    "        return 'купе'\n",
    "    elif s == 'WAGON':\n",
    "        return 'универсал'\n",
    "    elif s == 'ALLROAD':\n",
    "        return 'внедорожник'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "df[E] = df[field_name].apply(lambda x: extract_body_type_rus(x))\n",
    "print(\"Расхождений в типе кузова:\", df[ (df[E].notna()) & (df[E] != df.bodyType) ][E].count())\n",
    "df.drop([A, B, C, D, E], inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наши предположения полностью подтвердились\n",
    "\n",
    "Это значит, что поле `vehicleConfiguration` не информативно, и его можно отбросить за ненадобностью:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([field_name], inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vehicleTransmission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_name = 'vehicleTransmission'\n",
    "describe(df, field_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(train, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Доработаем трейн:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train[field_name] = train[field_name].apply(lambda x: 'роботизированная' if pd.notna(x) and x == 'робот' else x)\n",
    "describe(train, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим рассматриваемую колонку в список колонок единого датасета:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_cols.add(field_name)\n",
    "common_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### engineDisplacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_name = 'engineDisplacement'\n",
    "describe(df, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уберем неинформативный суффикс \"LTR\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[field_name] = df[field_name].apply(lambda x: x.split()[0])\n",
    "describe(df, field_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[df[field_name] == 'undefined']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы не можем заменить значение \"undefined\" ни на какой объем двигателя, потому что в данном случае речь идет об электрокаре"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В трейне есть аналогичное поле:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(train, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь есть только одно специфическое значение \"6.0+\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train[field_name] = train[field_name].apply(lambda x: \"6.0\" if pd.notna(x) and x == \"6.0+\" else x)\n",
    "describe(train, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим рассматриваемую колонку в список колонок единого датасета:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_cols.add(field_name)\n",
    "common_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### enginePower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "field_name = 'enginePower'\n",
    "describe(df, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уберем неинформативный суффикс \"LTR\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[field_name] = df[field_name].apply(lambda x: x.split()[0])\n",
    "describe(df, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В трейне есть аналогичное поле:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(train, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь нужно убрать ненужный суффикс \"л.с.\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def drop_suffix(x):\n",
    "    x = re.sub(r'\\s*л.с\\.?\\s*$', '', x)\n",
    "    return x\n",
    "train[field_name] = train[field_name].apply(lambda x: None if pd.isna(x) else drop_suffix(x))\n",
    "train[field_name].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим рассматриваемую колонку в список колонок единого датасета:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_cols.add(field_name)\n",
    "common_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "field_name = 'description'\n",
    "describe(df, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Непонятно, что полезного можно почерпнуть из этого поля\n",
    "\n",
    "Убираем из дальнейшего рассмотрения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([field_name], inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mileage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "field_name = 'mileage'\n",
    "describe(df, field_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "describe(train, 'mileage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим рассматриваемую колонку в список колонок единого датасета:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_cols.add(field_name)\n",
    "common_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Комплектация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "field_name = 'Комплектация'\n",
    "describe(df, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поле содержит json, значения из которого мы извлечем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "features = set()\n",
    "for s in df[field_name].unique().tolist():\n",
    "    if len(s) > 4:\n",
    "        decoded = json.loads(s[2:-2])\n",
    "        for segment in decoded:\n",
    "            name = segment['name']\n",
    "            for feature in segment['values']:\n",
    "                features.add(feature + '::' + name)\n",
    "print(\"Количество разных атрибутов комлектации:\", len(features))\n",
    "print(\"Список атрибутов комлектации:\")\n",
    "print(\"------------------------------\")\n",
    "for feature in sorted(list(features)):\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все эти атрибуты можно превратить в отдельные boolean (0|1) поля:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(feature, s):\n",
    "    (feature_name, segment_name) = feature.split('::')\n",
    "    if len(s) > 4:\n",
    "        decoded = json.loads(s[2:-2])\n",
    "        for segment in decoded:\n",
    "            if segment['name'] == segment_name:\n",
    "                for feature in segment['values']:\n",
    "                    if feature == feature_name:\n",
    "                        return 1\n",
    "    return 0\n",
    "for feature in sorted(list(features)):\n",
    "    df[feature] = df[field_name].apply(lambda x: 0 if pd.isna(x) else extract_feature(feature, x))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим несколько новых полей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for feature in ['Яндекс.Авто::Мультимедиа', 'Фаркоп::Прочее', 'Сиденья с массажем::Салон']:\n",
    "    print(df[feature].value_counts())\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В трейне про комлектацию есть следующие поля: `Электростеклоподъемники`, `Усилитель руля`, `Аудиосистема`, `Фары`, `Климат-контроль`, `Салон`, `Диски`\n",
    "\n",
    "Рассмотрим их по порядку:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Электростеклоподъемники"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(train, 'Электростеклоподъемники')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения \"передние и задние\" и \"только задние\" поля `Электростеклоподъемники` трейна можно соотнести с созданнами нами в тесте полями `Электростеклоподъёмники задние::Комфорт` и `Электростеклоподъёмники передние::Комфорт` (сразу добавим эти поля в список общих полей):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feature = 'Электростеклоподъёмники'\n",
    "source = 'Электростеклоподъемники'\n",
    "group = 'Комфорт'\n",
    "for kind in [\"задние\", \"передние\"]:\n",
    "    field_name = f'{feature} {kind}::{group}'\n",
    "    train[field_name] = train[source].apply(lambda x: 1 if pd.notna(x) and kind in x else 0)\n",
    "    describe(train, field_name)\n",
    "    common_cols.add(field_name)\n",
    "    \n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Усилитель руля"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(train, 'Усилитель руля')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поле трейна `Усилитель руля` можно соотнести с созданным нами в тесте полем `Усилитель руля::Комфорт` (сразу поместим это поле в список общих колонок):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature = 'Усилитель руля'\n",
    "group = 'Комфорт'\n",
    "source = feature\n",
    "field_name = f'{feature}::{group}'\n",
    "train[field_name] = train[source].apply(lambda x: 1 if pd.notna(x) else 0)\n",
    "describe(train, field_name)\n",
    "common_cols.add(field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Аудиосистема"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поле `Аудиосистема` трейна не стыкуется с созданным нами в тесте полями `Аудиосистема Hi-Fi::Мультимедиа`, `Аудиосистема с TV::Мультимедиа`, `Аудиосистема::Мультимедиа`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "describe(train, 'Аудиосистема')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Фары"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "describe(train, 'Фары')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значение \"ксеноновые\" поля `Фары` трейна можно соотнести с полем `Ксеноновые/Биксеноновые фары::Обзор` созданным нами в тесте, а значение \"светодиодные\" - с полем `Светодиодные фары::Обзор` (сразу занесем использованные поля в список общих полей):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = 'Фары'\n",
    "group = 'Обзор'\n",
    "\n",
    "feature = 'Ксеноновые/Биксеноновые фары'\n",
    "field_name = f'{feature}::{group}'\n",
    "mark = 'ксеноновые'\n",
    "train[field_name] = train[source].apply(lambda x: 1 if pd.notna(x) and mark in x else 0)\n",
    "common_cols.add(field_name)\n",
    "describe(train, field_name)\n",
    "print(\"\")\n",
    "\n",
    "feature = 'Светодиодные фары'\n",
    "field_name = f'{feature}::{group}'\n",
    "mark = 'светодиодные'\n",
    "train[field_name] = train[source].apply(lambda x: 1 if pd.notna(x) and mark in x else 0)\n",
    "common_cols.add(field_name)\n",
    "describe(train, field_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Климат-контроль"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(train, 'Климат-контроль')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значение \"климат-контроль многозонный\" можно соотнести с полем `Климат-контроль многозонный::Комфорт`, а значение \"климат-контроль однозонный\" - с полем `Климат-контроль 1-зонный::Комфорт` (сразу занесем эти поля в список общих):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "source = 'Климат-контроль'\n",
    "group = 'Комфорт'\n",
    "\n",
    "feature = 'Климат-контроль многозонный'\n",
    "field_name = f'{feature}::{group}'\n",
    "mark = 'многозонный'\n",
    "train[field_name] = train[source].apply(lambda x: 1 if pd.notna(x) and mark in x else 0)\n",
    "common_cols.add(field_name)\n",
    "describe(train, field_name)\n",
    "print(\"\")\n",
    "\n",
    "feature = 'Климат-контроль 1-зонный'\n",
    "field_name = f'{feature}::{group}'\n",
    "mark = 'однозонный'\n",
    "train[field_name] = train[source].apply(lambda x: 1 if pd.notna(x) and mark in x else 0)\n",
    "common_cols.add(field_name)\n",
    "describe(train, field_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Салон"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(train, 'Салон')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения можно соотнести следующим образом:\n",
    "    - \"ткань\" => `Ткань (Материал салона)::Салон`\n",
    "    - \"кожа\" => `Кожа (Материал салона)::Салон`\n",
    "    - \"велюр\" => `Велюр (Материал салона)::Салон`\n",
    "    - \"комбинированный\" => `Комбинированный (Материал салона)::Салон`\n",
    "Выполним это соответстие, сохранив использованные поля в списке общих полей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "source = 'Салон'\n",
    "group = 'Салон'\n",
    "\n",
    "feature = 'Ткань (Материал салона)'\n",
    "field_name = f'{feature}::{group}'\n",
    "mark = 'ткань'\n",
    "train[field_name] = train[source].apply(lambda x: 1 if pd.notna(x) and mark in x else 0)\n",
    "common_cols.add(field_name)\n",
    "describe(train, field_name)\n",
    "print(\"\")\n",
    "\n",
    "feature = 'Кожа (Материал салона)'\n",
    "field_name = f'{feature}::{group}'\n",
    "mark = 'кожа'\n",
    "train[field_name] = train[source].apply(lambda x: 1 if pd.notna(x) and mark in x else 0)\n",
    "common_cols.add(field_name)\n",
    "describe(train, field_name)\n",
    "print(\"\")\n",
    "\n",
    "feature = 'Велюр (Материал салона)'\n",
    "field_name = f'{feature}::{group}'\n",
    "mark = 'велюр'\n",
    "train[field_name] = train[source].apply(lambda x: 1 if pd.notna(x) and mark in x else 0)\n",
    "common_cols.add(field_name)\n",
    "describe(train, field_name)\n",
    "print(\"\")\n",
    "\n",
    "feature = 'Комбинированный (Материал салона)'\n",
    "field_name = f'{feature}::{group}'\n",
    "mark = 'комбинированный'\n",
    "train[field_name] = train[source].apply(lambda x: 1 if pd.notna(x) and mark in x else 0)\n",
    "common_cols.add(field_name)\n",
    "describe(train, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Диски"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "describe(train, 'Диски')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения можно соотнести следующим образом:\n",
    "    - '14\"' => `Диски 14::Элементы экстерьера`\n",
    "    - '15\"' => `Диски 15::Элементы экстерьера`\n",
    "    - '16\"' => `Диски 16::Элементы экстерьера`\n",
    "    - '17\"' => `Диски 17::Элементы экстерьера`\n",
    "    - '18\"' => `Диски 18::Элементы экстерьера`\n",
    "    - '19\"' => `Диски 19::Элементы экстерьера`\n",
    "    - '20\"' => `Диски 20::Элементы экстерьера`\n",
    "    - '21\"' => `Диски 21::Элементы экстерьера`\n",
    "    - '22\"' => `Диски 22::Элементы экстерьера`\n",
    "Выполним это соответстие, сохранив использованные поля в списке общих полей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "source = 'Диски'\n",
    "group = 'Элементы экстерьера'\n",
    "\n",
    "for i in range(14,23):\n",
    "    feature = f'Диски {i}'\n",
    "    field_name = f'{feature}::{group}'\n",
    "    mark = str(i)\n",
    "    train[field_name] = train[source].apply(lambda x: 1 if pd.notna(x) and mark in x else 0)\n",
    "    common_cols.add(field_name)\n",
    "    describe(train, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Привод"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "field_name = 'Привод'\n",
    "describe(df, field_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(train, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим рассматриваемую колонку в список колонок единого датасета:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_cols.add(field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Руль"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "field_name = 'Руль'\n",
    "describe(df, field_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "describe(train, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим рассматриваемую колонку в список колонок единого датасета:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_cols.add(field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Состояние"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "field_name = 'Состояние'\n",
    "describe(df, field_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "describe(train, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь совершенно про разное, машина может не требовать ремонта, но при этом быть \"битой\" (ранее попадала в аварию) и \"не битой\"\n",
    "\n",
    "При этом \"битые\" машины мы вряд ли будем выкупать, поэтому \"битые даже не должны доходить до нашей модели\n",
    "\n",
    "Исключим все \"битые\" из трейна, но колонку \"Состояние\" в список общих колонок добавлять не будем, так как не информативна в данном случае"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[ train[field_name].map(lambda x: 1 if pd.notna(x) and x == \"Битый\" else 0) == 0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(train, field_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Владельцы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "field_name = 'Владельцы'\n",
    "describe(df, field_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(train, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приведем значения датасетов к общему знаменателю: \"1\", \"2\", \"3\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[field_name] = df[field_name].apply(lambda x: x[0])\n",
    "train[field_name] = train[field_name].apply(lambda x: None if pd.isna(x) else x[0] if int(x[0]) < 4 else \"3\")\n",
    "describe(df, field_name)\n",
    "describe(train, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим рассматриваемую колонку в список колонок единого датасета:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_cols.add(field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ПТС"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "field_name = 'ПТС'\n",
    "describe(df, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогов в трейне не обнаружено"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Таможня"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_name = 'Таможня'\n",
    "describe(df, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогов в трейне не обнаружено"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Владение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "field_name = 'Владение'\n",
    "describe(df, field_name)\n",
    "df[field_name].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем в количество месяцев:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(x):\n",
    "    if x is None:\n",
    "        return None\n",
    "    else:\n",
    "        found_month = re.search('^(\\d+) месяц(?:а|ев)?', x)\n",
    "        if found_month:\n",
    "            return found_month.group(1)   \n",
    "        else:\n",
    "            found_year_month = re.search('^(\\d+) (?:года?|лет)(?: и (\\d+) месяц(?:а|ев)?)?', x)\n",
    "            if found_year_month is None:\n",
    "                print(x)\n",
    "                return None\n",
    "            else:\n",
    "                if found_year_month.group(2) is None:                   \n",
    "                    return int(found_year_month.group(1)) * 12\n",
    "                else:\n",
    "                    return int(found_year_month.group(1)) * 12 + int(found_year_month.group(2))\n",
    "df[field_name] = df[field_name].apply(lambda x: None if pd.isna(x) else transform(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогов в трейне не обнаружено"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сведение в единый датасет\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим состав общих полей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Общих полей:\", len(common_cols))\n",
    "print(\"------------\")\n",
    "for field_name in sorted(list(common_cols)):\n",
    "    print(field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим в трейн и в тест поле-маркер `is_train`, добавив это поле в список общих полей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_name = 'is_train'\n",
    "test[field_name] = 0\n",
    "train[field_name] = 1\n",
    "common_cols.add(field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим в тестовый датасет поле `price`, поместим в это же поле значение целевой переменной в трейне из поля `itemPrice`, и добавим поле `price` в список общих полей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_name = 'price'\n",
    "test[field_name] = None\n",
    "train[field_name] = train['itemPrice']\n",
    "common_cols.add(field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "и объедим два датасета в один:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "common_cols = sorted(list(common_cols))\n",
    "common_df_orig = test[common_cols].append(train[common_cols], sort=False).reset_index(drop=True)\n",
    "print(common_df_orig.info(verbose=True))\n",
    "df = common_df_orig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прежде, чем мы приступим к обучению модели, добавим еще несколько features нашему датасету:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Налог"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим колонку \"Налог\", в котором укажем размер ежегодного налога на автомобиль согласно https://glavkniga.ru/situations/s509668:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(df, 'fuelType')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_name = 'Налог'\n",
    "def calc_tax(x):\n",
    "    x = int(x)\n",
    "    return x*12 if x<=100 else x*25 if x>100 and x<=125 else x*35 if x>125 and x<=150 else x*45 if x>150 and x<=175 else x*55 if x>175 and x<=200 else x*65 if x>200 and x<=225 else x*75 if x>225 and x<=250 else x*150\n",
    "df[field_name] = df.apply(lambda row: \n",
    "                          0 if row['fuelType'] == 'электро' else \n",
    "                          None if pd.isna(row['enginePower']) else calc_tax(row['enginePower']), \n",
    "                            axis=1\n",
    "                         )\n",
    "# df[]\n",
    "describe(df, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Время эксплуатации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_name = 'Время эксплуатации'\n",
    "source = 'productionDate'\n",
    "df[field_name] = 2021 - df[source]\n",
    "describe(df, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Средний пробег"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "field_name = 'Средний пробег'\n",
    "df[field_name] = df['mileage'].astype(float) / df['Время эксплуатации'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Преобразование типов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_name = 'engineDisplacement'\n",
    "df[field_name] = df[field_name].apply(lambda x: 0 if pd.isna(x) or x == 'undefined' else int(float(x) * 10))\n",
    "describe(df, field_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_name = 'price'\n",
    "df[field_name] = df[field_name].fillna(0).astype(np.int)\n",
    "\n",
    "field_name = 'engineDisplacement'\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "for field_name in [\n",
    "    'enginePower', \n",
    "    'mileage', \n",
    "    'numberOfDoors', \n",
    "    'productionDate', \n",
    "    'Владельцы',\n",
    "    'Налог', \n",
    "    'Время эксплуатации', \n",
    "    'Средний пробег'\n",
    "]:\n",
    "    df[field_name] = df[field_name].astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_df_orig = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка submission'a для kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим функцию для подготовки submission для kaggle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_submission_url = \"https://drive.google.com/u/0/uc?id=1XktGbf7aLmAd_eyTBL0YGYGXV8WLN5e1&export=download\"\n",
    "sample_submission_orig = pd.read_csv(sample_submission_url)\n",
    "def make_submission(model, version, tag):\n",
    "    predict_submission = model.predict(test)\n",
    "    sample_submission = sample_submission_orig.copy()\n",
    "    sample_submission['price'] = predict_submission\n",
    "    sample_submission.price = sample_submission.price.astype(np.int32)\n",
    "    sample_submission.to_csv(f'submission_v{version}_{tag}.csv', index=False)\n",
    "    sample_submission.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка модели\n",
    "\n",
    "Определим функции для оценки модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred1 = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true))\n",
    "\n",
    "def print_regression_metrics(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    print(f'RMSE = {rmse:.2f}, MAE = {mae:.2f}, R-sq = {r2:.2f}, MAPE = {mape:.2f} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Случайный лес"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем использовать для обучения модели Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим label encoding ко всем строковым поля:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "df = common_df_orig.copy()\n",
    "for field_name in ['bodyType', 'brand', 'color', 'fuelType', 'vehicleTransmission', 'Привод', 'Руль', 'model']:\n",
    "    v = df[field_name].values.tolist()\n",
    "    encoder.fit(v)\n",
    "    df[field_name] = encoder.transform(df[field_name])\n",
    "    describe(df, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разъединяем датасеты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.query('is_train==1').drop(['is_train'], axis = 1)\n",
    "test = df.query('is_train==0').drop(['is_train', 'price'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим выборки для обучения и проверки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_SIZE = 0.3\n",
    "RANDOM_SEED = 77\n",
    "from sklearn.model_selection import train_test_split\n",
    "target_field_name = 'price'\n",
    "X = train.drop([target_field_name],axis=1)\n",
    "y = train[target_field_name]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, test_size = VAL_SIZE, random_state=RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from collections import defaultdict\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "model = RandomForestRegressor(n_estimators=30, max_features=10,  max_depth = 20, random_state=RANDOM_SEED) #max_depth = 15, min_samples_leaf = 1, min_samples_split = 5, n_estimators = 100, verbose = 100)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print_regression_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим submission для kaggle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_submission(model, VERSION, 'random_forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем использовать для обучения модели LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим label encoding ко всем строковым поля:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "df = common_df_orig.copy()\n",
    "for field_name in ['bodyType', 'brand', 'color', 'fuelType', 'vehicleTransmission', 'Привод', 'Руль', 'model']:\n",
    "    v = df[field_name].values.tolist()\n",
    "    encoder.fit(v)\n",
    "    df[field_name] = encoder.transform(df[field_name])\n",
    "    describe(df, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LightGBM требует только английские буквы в названии колонок:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/14173421/use-string-translate-in-python-to-transliterate-cyrillic\n",
    "symbols = (u\"абвгдеёжзийклмнопрстуфхцчшщъыьэюяАБВГДЕЁЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯ :()\",\n",
    "           u\"abvgdeejzijklmnoprstufhzcss_y_euaABVGDEEJZIJKLMNOPRSTUFHZCSS_Y_EUA____\")\n",
    "tr = {ord(a):ord(b) for a, b in zip(*symbols)}\n",
    "rename_map = {}\n",
    "for col in df.columns.tolist():\n",
    "    field_name = col.translate(tr)\n",
    "    rename_map[col] = col.translate(tr)\n",
    "df.rename(columns=rename_map, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разъединяем датасеты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.query('is_train==1').drop(['is_train'], axis = 1)\n",
    "test = df.query('is_train==0').drop(['is_train', 'price'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим данные для обучения и проверки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_SIZE = 0.3\n",
    "RANDOM_SEED = 77\n",
    "from sklearn.model_selection import train_test_split\n",
    "target_field_name = 'price'\n",
    "X = train.drop([target_field_name],axis=1)\n",
    "y = train[target_field_name]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, test_size = VAL_SIZE, random_state=RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "model = lgb.LGBMRegressor(random_state=RANDOM_SEED)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print_regression_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим submission для kaggle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_submission(model, VERSION, 'ligthgbm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost\n",
    "\n",
    "Для обучения модели будем использовать [Catboost](https://catboost.ai/):\n",
    "\n",
    "Сначала разъединим датасеты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = common_df_orig.copy()\n",
    "train = df.query('is_train==1').drop(['is_train'], axis = 1)\n",
    "test = df.query('is_train==0').drop(['is_train', 'price'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим выборки для обучения и проверки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "VAL_SIZE   = 0.30\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "target_field_name = 'price'\n",
    "X = train.drop([target_field_name],axis=1)\n",
    "y = train[target_field_name]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, test_size = VAL_SIZE, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics \n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# CATBOOST\n",
    "ITERATIONS = 10000\n",
    "LR         = 0.1\n",
    "cat_features_ids = np.where(X_train.apply(pd.Series.nunique) < 3000)[0].tolist()\n",
    "model = CatBoostRegressor(iterations = ITERATIONS,\n",
    "                          learning_rate = LR,\n",
    "                          random_seed = RANDOM_SEED,\n",
    "                          eval_metric='MAPE',\n",
    "                          custom_metric=['R2', 'MAE']\n",
    "                         )\n",
    "model.fit(X_train, y_train,\n",
    "         cat_features=cat_features_ids,\n",
    "         eval_set=(X_test, y_test),\n",
    "         verbose_eval=100,\n",
    "         use_best_model=True,\n",
    "         plot=True\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model('catboost_single_model_baseline.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получим оценки модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print_regression_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим влияние параметров на целевую переменную:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features_importances = pd.DataFrame(data = model.feature_importances_, index = X.columns, columns = ['FeatImportant'])\n",
    "features_importances.sort_values(by = 'FeatImportant', ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим submission для kaggle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_submission(model, VERSION, 'catboost')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дополнительно применим блендинг:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N_FOLDS    = 10\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "def cat_model(y_train, X_train, X_test, y_test):\n",
    "    model = CatBoostRegressor(iterations = ITERATIONS,\n",
    "                              learning_rate = LR,\n",
    "                              eval_metric='MAPE',\n",
    "                              random_seed = RANDOM_SEED,)\n",
    "    model.fit(X_train, y_train,\n",
    "              cat_features=cat_features_ids,\n",
    "              eval_set=(X_test, y_test),\n",
    "              verbose=False,\n",
    "              use_best_model=True,\n",
    "              plot=False)\n",
    "    return(model)\n",
    "def mape(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_pred-y_true)/y_true))\n",
    "sample_submission = sample_submission_orig.copy()\n",
    "\n",
    "submissions = pd.DataFrame(0,columns=[\"sub_1\"], index=sample_submission.index) # куда пишем предикты по каждой модели\n",
    "score_ls = []\n",
    "splits = list(KFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDOM_SEED).split(X, y))\n",
    "for idx, (train_idx, test_idx) in tqdm(enumerate(splits), total=N_FOLDS,):\n",
    "    # use the indexes to extract the folds in the train and validation data\n",
    "    X_train, y_train, X_test, y_test = X.iloc[train_idx], y.iloc[train_idx], X.iloc[test_idx], y.iloc[test_idx]\n",
    "    # model for this fold\n",
    "    model = cat_model(y_train, X_train, X_test, y_test,)\n",
    "    # score model on test\n",
    "    test_predict = model.predict(X_test)\n",
    "    test_score = mape(y_test, test_predict)\n",
    "    score_ls.append(test_score)\n",
    "    print(f\"{idx+1} Fold Test MAPE: {mape(y_test, test_predict):0.3f}\")\n",
    "    # submissions\n",
    "    submissions[f'sub_{idx+1}'] = model.predict(test)\n",
    "    model.save_model(f'catboost_fold_{idx+1}.model')\n",
    "print(f'Mean Score: {np.mean(score_ls):0.3f}')\n",
    "print(f'Std Score: {np.std(score_ls):0.4f}')\n",
    "print(f'Max Score: {np.max(score_ls):0.3f}')\n",
    "print(f'Min Score: {np.min(score_ls):0.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получим оценки модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print_regression_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим submission для kaggle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_submission(model, VERSION, 'catboost_blended')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
